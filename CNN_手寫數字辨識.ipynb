{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.匯入相關庫，通過網路下載並接收手寫mnist數字庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# 下載並載入MNIST手寫數字庫(55000 * 28 * 28)55000張訓練影象\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-1be209998982>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting Mnist_Data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting Mnist_Data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting Mnist_Data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting Mnist_Data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('Mnist_Data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one_hot是一種編碼形式，獨熱碼的編碼（encoding）形式 \n",
    "\n",
    "0， 1， 2， 3， 4， 5， 6， 7， 8， 9的十位數字\n",
    "\n",
    "one_hot=True 就會表示成下面的編碼模式：\n",
    "\n",
    "# 0:1000000000\n",
    "# 1:0100000000\n",
    "# 2:0010000000\n",
    "# 3:0001000000\n",
    "# 4:0000100000\n",
    "# 5:0000010000\n",
    "# 6:0000001000\n",
    "# 7:0000000100\n",
    "# 8:0000000010\n",
    "# 9:0000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.設定卷積神經網路輸入張量及測試資料 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None 表示張量（Tensor）的第一個維度可以是任何長度\n",
    "input_x = tf.placeholder(tf.float32, [None, 28*28]) / 255.\n",
    "output_y = tf.placeholder(tf.int32, [None, 10]) # 輸出：10個數字的標籤\n",
    "input_x_images = tf.reshape(input_x, [-1, 28, 28, 1]) # 改變形狀之後的輸入\n",
    "\n",
    "# Test（測試）資料集裡選取3000個手寫數字的圖片和對應標籤\n",
    "test_x = mnist.test.images[:3000] # 圖片\n",
    "test_y = mnist.test.labels[:3000] # 標籤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# None 表示張量（Tensor）的第一個維度可以是任何長度。\n",
    "# Test（測試）資料集裡選取3000個手寫數字的圖片和對應標籤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.分層構建卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-c9467518a479>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\SeA\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-c9467518a479>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-c9467518a479>:39: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-c9467518a479>:42: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "# 第1層卷積 \n",
    "conv1 = tf.layers.conv2d(\n",
    "\tinputs=input_x_images,\t# 形狀 [28， 28， 1]\n",
    "\tfilters=32,\t\t# 32個過濾器， 輸出的深度（depth）是32\n",
    "\tkernel_size=[5, 5],\t# 過濾器在二維的大小是(5 * 5)\n",
    "\tstrides=1,\t\t# 步長是1\n",
    "\tpadding='same',\t\t# same表示輸出的大小不變，因此需要在外圍補零2圈\n",
    "\tactivation=tf.nn.relu\t# 啟用函式是Relu\n",
    ")\t# 形狀 [28, 28, 32]\n",
    "\n",
    "# 第1層池化（亞取樣）\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "\tinputs=conv1,\t\t\t# 形狀 [28, 28, 32]\n",
    "\tpool_size=[2, 2],\t\t# 過濾器在二維的大小是(2 * 2)\t\t\n",
    "\tstrides=2\t\t\t# 步長是2\n",
    ")\t# 形狀[14, 14, 32]\n",
    "\n",
    "# 第2層卷積\n",
    "conv2 = tf.layers.conv2d(\n",
    "\tinputs=pool1,\t\t\t# 形狀 [14, 14, 32]\n",
    "\tfilters=64,\t\t\t# 64個過濾器， 輸出的深度（depth）是64\n",
    "\tkernel_size=[5, 5],\t\t# 過濾器在二維的大小是(5 * 5)\n",
    "\tstrides=1,\t\t\t# 步長是1\n",
    "\tpadding='same',\t\t\t# same表示輸出的大小不變，因此需要在外圍補零2圈\n",
    "\tactivation=tf.nn.relu\t\t# 啟用函式是Relu\n",
    ")\t# 形狀 [14, 14, 64]\n",
    "\n",
    "# 第2層池化（亞取樣）\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "\tinputs=conv2,\t\t\t# 形狀 [14, 14, 64]\n",
    "\tpool_size=[2, 2]\t,\t# 過濾器在二維的大小是(2 * 2)\t\t\n",
    "\tstrides=2\t\t\t# 步長是2\n",
    ")\t# 形狀[7, 7, 64]\n",
    "\n",
    "# 平坦化（flat）\n",
    "flat = tf.reshape(pool2, [-1, 7 * 7 *64])\t# 形狀 [7 * 7 * 64]\n",
    "\n",
    "# 1024 個神經元的全連線層\n",
    "dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "# Dropout：丟棄50%，rate=0.5\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "\n",
    "# 10個神經元的全連線層，這裡不用啟用函式做非線性化\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)\t# 輸出形狀[1, 1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.最小化誤差及計算精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算誤差（計算Cross entropy（交叉熵），再用Softmax計算出百分比概率）\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=output_y, logits=logits)\n",
    "\n",
    "# 用Adam優化器來最小化誤差，學習率 0.001\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "# 計算預測值和實際標籤的匹配程度（精度）\n",
    "# 返回（accuracy, update_op）,會建立兩個區域性變數\n",
    "accuracy = tf.metrics.accuracy(\n",
    "\tlabels=tf.argmax(output_y, axis=1),\n",
    "\tpredictions=tf.argmax(logits, axis=1),)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我們使用的是adam優化器進行誤差的最小化，此處我們的學習率為0.001 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.訓練神經網路並測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=0, Train loss=2.2873, [Test accuracy=0.26]\n",
      "Step=100, Train loss=0.0563, [Test accuracy=0.59]\n",
      "Step=200, Train loss=0.0642, [Test accuracy=0.71]\n",
      "Step=300, Train loss=0.0449, [Test accuracy=0.78]\n",
      "Step=400, Train loss=0.0468, [Test accuracy=0.81]\n",
      "Step=500, Train loss=0.0271, [Test accuracy=0.84]\n",
      "Step=600, Train loss=0.0133, [Test accuracy=0.86]\n",
      "Step=700, Train loss=0.0585, [Test accuracy=0.88]\n",
      "Step=800, Train loss=0.0406, [Test accuracy=0.89]\n",
      "Step=900, Train loss=0.0312, [Test accuracy=0.90]\n",
      "Step=1000, Train loss=0.0590, [Test accuracy=0.90]\n",
      "Step=1100, Train loss=0.0404, [Test accuracy=0.91]\n",
      "Step=1200, Train loss=0.0942, [Test accuracy=0.92]\n",
      "Step=1300, Train loss=0.0602, [Test accuracy=0.92]\n",
      "Step=1400, Train loss=0.0775, [Test accuracy=0.92]\n",
      "Step=1500, Train loss=0.0046, [Test accuracy=0.93]\n",
      "Step=1600, Train loss=0.0198, [Test accuracy=0.93]\n",
      "Step=1700, Train loss=0.0152, [Test accuracy=0.93]\n",
      "Step=1800, Train loss=0.0237, [Test accuracy=0.94]\n",
      "Step=1900, Train loss=0.0918, [Test accuracy=0.94]\n",
      "Step=2000, Train loss=0.0049, [Test accuracy=0.94]\n",
      "Step=2100, Train loss=0.0015, [Test accuracy=0.94]\n",
      "Step=2200, Train loss=0.0919, [Test accuracy=0.95]\n",
      "Step=2300, Train loss=0.0525, [Test accuracy=0.95]\n",
      "Step=2400, Train loss=0.0482, [Test accuracy=0.95]\n",
      "Step=2500, Train loss=0.0049, [Test accuracy=0.95]\n",
      "Step=2600, Train loss=0.0245, [Test accuracy=0.95]\n",
      "Step=2700, Train loss=0.0523, [Test accuracy=0.95]\n",
      "Step=2800, Train loss=0.0113, [Test accuracy=0.95]\n",
      "Step=2900, Train loss=0.0900, [Test accuracy=0.95]\n",
      "Step=3000, Train loss=0.0041, [Test accuracy=0.95]\n",
      "Step=3100, Train loss=0.0153, [Test accuracy=0.96]\n",
      "Step=3200, Train loss=0.0346, [Test accuracy=0.96]\n",
      "Step=3300, Train loss=0.1006, [Test accuracy=0.96]\n",
      "Step=3400, Train loss=0.0026, [Test accuracy=0.96]\n",
      "Step=3500, Train loss=0.0001, [Test accuracy=0.96]\n",
      "Step=3600, Train loss=0.0003, [Test accuracy=0.96]\n",
      "Step=3700, Train loss=0.0034, [Test accuracy=0.96]\n",
      "Step=3800, Train loss=0.0013, [Test accuracy=0.96]\n",
      "Step=3900, Train loss=0.0230, [Test accuracy=0.96]\n",
      "Step=4000, Train loss=0.3678, [Test accuracy=0.96]\n",
      "Step=4100, Train loss=0.0005, [Test accuracy=0.96]\n",
      "Step=4200, Train loss=0.0012, [Test accuracy=0.96]\n",
      "Step=4300, Train loss=0.0022, [Test accuracy=0.96]\n",
      "Step=4400, Train loss=0.0007, [Test accuracy=0.96]\n",
      "Step=4500, Train loss=0.0007, [Test accuracy=0.97]\n",
      "Step=4600, Train loss=0.0245, [Test accuracy=0.97]\n",
      "Step=4700, Train loss=0.0000, [Test accuracy=0.97]\n",
      "Step=4800, Train loss=0.0018, [Test accuracy=0.97]\n",
      "Step=4900, Train loss=0.0054, [Test accuracy=0.97]\n",
      "Step=5000, Train loss=0.0002, [Test accuracy=0.97]\n",
      "Step=5100, Train loss=0.0000, [Test accuracy=0.97]\n",
      "Step=5200, Train loss=0.0001, [Test accuracy=0.97]\n",
      "Step=5300, Train loss=0.0779, [Test accuracy=0.97]\n",
      "Step=5400, Train loss=0.0033, [Test accuracy=0.97]\n",
      "Step=5500, Train loss=0.0024, [Test accuracy=0.97]\n",
      "Step=5600, Train loss=0.0008, [Test accuracy=0.97]\n",
      "Step=5700, Train loss=0.0023, [Test accuracy=0.97]\n",
      "Step=5800, Train loss=0.1170, [Test accuracy=0.97]\n",
      "Step=5900, Train loss=0.0023, [Test accuracy=0.97]\n",
      "Step=6000, Train loss=0.0015, [Test accuracy=0.97]\n",
      "Step=6100, Train loss=0.0006, [Test accuracy=0.97]\n",
      "Step=6200, Train loss=0.0002, [Test accuracy=0.97]\n",
      "Step=6300, Train loss=0.0002, [Test accuracy=0.97]\n",
      "Step=6400, Train loss=0.0001, [Test accuracy=0.97]\n",
      "Step=6500, Train loss=0.0057, [Test accuracy=0.97]\n",
      "Step=6600, Train loss=0.0034, [Test accuracy=0.97]\n",
      "Step=6700, Train loss=0.0000, [Test accuracy=0.97]\n",
      "Step=6800, Train loss=0.0049, [Test accuracy=0.97]\n",
      "Step=6900, Train loss=0.0039, [Test accuracy=0.97]\n",
      "Step=7000, Train loss=0.0015, [Test accuracy=0.97]\n",
      "Step=7100, Train loss=0.0191, [Test accuracy=0.97]\n",
      "Step=7200, Train loss=0.0142, [Test accuracy=0.97]\n",
      "Step=7300, Train loss=0.0110, [Test accuracy=0.97]\n",
      "Step=7400, Train loss=0.0004, [Test accuracy=0.97]\n",
      "Step=7500, Train loss=0.0068, [Test accuracy=0.97]\n",
      "Step=7600, Train loss=0.0005, [Test accuracy=0.97]\n",
      "Step=7700, Train loss=0.0335, [Test accuracy=0.97]\n",
      "Step=7800, Train loss=0.0012, [Test accuracy=0.97]\n",
      "Step=7900, Train loss=0.0059, [Test accuracy=0.97]\n",
      "Step=8000, Train loss=0.0003, [Test accuracy=0.97]\n",
      "Step=8100, Train loss=0.0005, [Test accuracy=0.97]\n",
      "Step=8200, Train loss=0.0000, [Test accuracy=0.97]\n",
      "Step=8300, Train loss=0.0002, [Test accuracy=0.97]\n",
      "Step=8400, Train loss=0.0005, [Test accuracy=0.97]\n",
      "Step=8500, Train loss=0.0006, [Test accuracy=0.98]\n",
      "Step=8600, Train loss=0.0084, [Test accuracy=0.98]\n",
      "Step=8700, Train loss=0.0001, [Test accuracy=0.98]\n",
      "Step=8800, Train loss=0.0014, [Test accuracy=0.98]\n",
      "Step=8900, Train loss=0.3869, [Test accuracy=0.98]\n",
      "Step=9000, Train loss=0.0004, [Test accuracy=0.98]\n",
      "Step=9100, Train loss=0.0004, [Test accuracy=0.98]\n",
      "Step=9200, Train loss=0.0001, [Test accuracy=0.98]\n",
      "Step=9300, Train loss=0.0002, [Test accuracy=0.98]\n",
      "Step=9400, Train loss=0.0182, [Test accuracy=0.98]\n",
      "Step=9500, Train loss=0.1360, [Test accuracy=0.98]\n",
      "Step=9600, Train loss=0.0000, [Test accuracy=0.98]\n",
      "Step=9700, Train loss=0.0000, [Test accuracy=0.98]\n",
      "Step=9800, Train loss=0.0028, [Test accuracy=0.98]\n",
      "Step=9900, Train loss=0.0000, [Test accuracy=0.98]\n",
      "Step=10000, Train loss=0.0038, [Test accuracy=0.98]\n",
      "Step=10100, Train loss=0.0001, [Test accuracy=0.98]\n",
      "Step=10200, Train loss=0.0000, [Test accuracy=0.98]\n",
      "Step=10300, Train loss=0.0010, [Test accuracy=0.98]\n",
      "Step=10400, Train loss=0.0006, [Test accuracy=0.98]\n",
      "Step=10500, Train loss=0.0002, [Test accuracy=0.98]\n",
      "Step=10600, Train loss=0.0030, [Test accuracy=0.98]\n",
      "Step=10700, Train loss=0.0000, [Test accuracy=0.98]\n",
      "Step=10800, Train loss=0.0012, [Test accuracy=0.98]\n",
      "Step=10900, Train loss=0.0001, [Test accuracy=0.98]\n",
      "Step=11000, Train loss=0.0726, [Test accuracy=0.98]\n",
      "Step=11100, Train loss=0.0016, [Test accuracy=0.98]\n",
      "Step=11200, Train loss=0.0001, [Test accuracy=0.98]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6029e8f224d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#從Train（訓練)資料集裡取下一個50樣本\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Python 3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 建立會話\n",
    "sess = tf.Session()\n",
    "\n",
    "# 初始化變數：\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "\n",
    "# 訓練神經網路\n",
    "for i in range(20000):\n",
    "\tbatch = mnist.train.next_batch(50) #從Train（訓練)資料集裡取下一個50樣本\n",
    "\ttrain_loss, _ = sess.run([loss, train_op], {input_x: batch[0], output_y: batch[1]})\n",
    "\tif i % 100 == 0:\n",
    "\t\ttest_accuracy = sess.run(accuracy, {input_x: test_x, output_y: test_y})\n",
    "\t\tprint(\"Step=%d, Train loss=%.4f, [Test accuracy=%.2f]\" % (i, train_loss, test_accuracy))\n",
    "\n",
    "# 測試：列印20個測試值和真實值\n",
    "test_output = sess.run(logits, {input_x: test_x[:20]})\n",
    "inferenced_y = np.argmax(test_output, 1)\n",
    "print(inferenced_y, 'Inferenced numbers') # 推測的數字\n",
    "print(np.argmax(test_y[:20], 1), 'Real numbers') # 真實的數字\n",
    "\n",
    "# 關閉會話\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試：輸出20個測試值和真實值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] Inferenced numbers\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] Real numbers\n"
     ]
    }
   ],
   "source": [
    "test_output = sess.run(logits, {input_x: test_x[:20]})\n",
    "inferenced_y = np.argmax(test_output, 1)\n",
    "print(inferenced_y, 'Inferenced numbers') # 推測的數字\n",
    "print(np.argmax(test_y[:20], 1), 'Real numbers') # 真實的數字"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
